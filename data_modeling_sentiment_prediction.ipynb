{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "503aa622",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "851770c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jillian/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/jillian/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/jillian/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/jillian/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "#Required text pre-processing libraries are imported\n",
    "import string\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "# download the stopwords and wordnet corpus\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "# import tokenize from nltk library\n",
    "from nltk import tokenize\n",
    "# import WordNetLemmatizer from nltk library\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "#Required data visualisation libraries are imported\n",
    "import plotly.express as px\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#Required prediction modelling libraries are imported\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import plot_confusion_matrix, confusion_matrix, precision_recall_curve, auc, roc_curve, accuracy_score, recall_score, classification_report, f1_score, precision_score, precision_recall_fscore_support, roc_auc_score, make_scorer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImPipeline\n",
    "\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import pickle\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a161603",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d5a0875",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/singe_word_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d0185da",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clothing_ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review_Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended_IND</th>\n",
       "      <th>Positive_Feedback_Count</th>\n",
       "      <th>Division_Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>Class_Name</th>\n",
       "      <th>Clean</th>\n",
       "      <th>String</th>\n",
       "      <th>Positive_Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>767</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Initmates</td>\n",
       "      <td>Intimate</td>\n",
       "      <td>Intimates</td>\n",
       "      <td>['absolutely', 'wonderful', 'silky', 'sexy', '...</td>\n",
       "      <td>absolutely wonderful silky sexy comfortable</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1080</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>['sooo', 'pretty', 'happened', 'find', 'store'...</td>\n",
       "      <td>sooo pretty happened find store glad bc never ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>['high', 'hope', 'wanted', 'work', 'initially'...</td>\n",
       "      <td>high hope wanted work initially petite usual f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1049</td>\n",
       "      <td>50</td>\n",
       "      <td>My favorite buy!</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "      <td>['jumpsuit', 'fun', 'flirty', 'fabulous', 'eve...</td>\n",
       "      <td>jumpsuit fun flirty fabulous every time get no...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>847</td>\n",
       "      <td>47</td>\n",
       "      <td>Flattering shirt</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "      <td>['shirt', 'flattering', 'due', 'adjustable', '...</td>\n",
       "      <td>shirt flattering due adjustable front tie perf...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Clothing_ID  Age                    Title  \\\n",
       "0          767   33                      NaN   \n",
       "1         1080   34                      NaN   \n",
       "2         1077   60  Some major design flaws   \n",
       "3         1049   50         My favorite buy!   \n",
       "4          847   47         Flattering shirt   \n",
       "\n",
       "                                         Review_Text  Rating  Recommended_IND  \\\n",
       "0  Absolutely wonderful - silky and sexy and comf...       4                1   \n",
       "1  Love this dress!  it's sooo pretty.  i happene...       5                1   \n",
       "2  I had such high hopes for this dress and reall...       3                0   \n",
       "3  I love, love, love this jumpsuit. it's fun, fl...       5                1   \n",
       "4  This shirt is very flattering to all due to th...       5                1   \n",
       "\n",
       "   Positive_Feedback_Count   Division_Name Department Name Class_Name  \\\n",
       "0                        0       Initmates        Intimate  Intimates   \n",
       "1                        4         General         Dresses    Dresses   \n",
       "2                        0         General         Dresses    Dresses   \n",
       "3                        0  General Petite         Bottoms      Pants   \n",
       "4                        6         General            Tops    Blouses   \n",
       "\n",
       "                                               Clean  \\\n",
       "0  ['absolutely', 'wonderful', 'silky', 'sexy', '...   \n",
       "1  ['sooo', 'pretty', 'happened', 'find', 'store'...   \n",
       "2  ['high', 'hope', 'wanted', 'work', 'initially'...   \n",
       "3  ['jumpsuit', 'fun', 'flirty', 'fabulous', 'eve...   \n",
       "4  ['shirt', 'flattering', 'due', 'adjustable', '...   \n",
       "\n",
       "                                              String  Positive_Rating  \n",
       "0        absolutely wonderful silky sexy comfortable                1  \n",
       "1  sooo pretty happened find store glad bc never ...                1  \n",
       "2  high hope wanted work initially petite usual f...                0  \n",
       "3  jumpsuit fun flirty fabulous every time get no...                1  \n",
       "4  shirt flattering due adjustable front tie perf...                1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccbc0150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22640 entries, 0 to 22639\n",
      "Data columns (total 13 columns):\n",
      " #   Column                   Non-Null Count  Dtype \n",
      "---  ------                   --------------  ----- \n",
      " 0   Clothing_ID              22640 non-null  int64 \n",
      " 1   Age                      22640 non-null  int64 \n",
      " 2   Title                    19675 non-null  object\n",
      " 3   Review_Text              22640 non-null  object\n",
      " 4   Rating                   22640 non-null  int64 \n",
      " 5   Recommended_IND          22640 non-null  int64 \n",
      " 6   Positive_Feedback_Count  22640 non-null  int64 \n",
      " 7   Division_Name            22627 non-null  object\n",
      " 8   Department Name          22627 non-null  object\n",
      " 9   Class_Name               22627 non-null  object\n",
      " 10  Clean                    22640 non-null  object\n",
      " 11  String                   22636 non-null  object\n",
      " 12  Positive_Rating          22640 non-null  int64 \n",
      "dtypes: int64(6), object(7)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9823b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Clothing_ID                   0\n",
       "Age                           0\n",
       "Title                      2965\n",
       "Review_Text                   0\n",
       "Rating                        0\n",
       "Recommended_IND               0\n",
       "Positive_Feedback_Count       0\n",
       "Division_Name                13\n",
       "Department Name              13\n",
       "Class_Name                   13\n",
       "Clean                         0\n",
       "String                        4\n",
       "Positive_Rating               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4583292e",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4eb71ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#will be using accuracy as metric; want to identify neutral/negative sentiments and be able\n",
    "#to sample enough of them to get a clear view of if there is a consistent issue\n",
    "#that we as a company can change for our soft roll out\n",
    "#also want to be able to ball park which items will be most popular, so we can have\n",
    "#an appropriate amount of inventory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029122cb",
   "metadata": {},
   "source": [
    "For each model we created a pipeline that includes a TF-IDF vectorizer, a smote component to deal with class imbalance, and the classifier itself. We elected to use a TF-IDF vectorizer instead of a count vectorizer because it provides a way to understand the importance of each word to the tweet, as well as just how frequently it occurs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177fba99",
   "metadata": {},
   "source": [
    "To give the model a little bit more information with those same features, we'll use a TfidfVectorizer (documentation here) so that it counts not only the term frequency (tf) within a single document, it also includes the inverse document frequency (idf) â€” how rare the term is.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b947d49f",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb869168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify X as the cleaned strings in df and y as the target-Positive_Rating.\n",
    "X = df['String']\n",
    "y = df['Positive_Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15f34bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performed the train-test split, using 20% for the hold-out data.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    random_state=42,\n",
    "                                                    test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "448ec345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19805                        contrast much prettier person\n",
       "11396    better hanger ive looking feminine plaid flirt...\n",
       "7884     wasnt much question whether id pant several pa...\n",
       "21304    legging warm comfortable theyre thick enough p...\n",
       "7216                     much lower quality robe purchased\n",
       "                               ...                        \n",
       "11964    bought grey gorgeous long length arm though tr...\n",
       "21575    pretty fun see tone subtle pretty beading neck...\n",
       "5390     bought tee washed time luckily hole yet review...\n",
       "860      excited see jean since came petite short insea...\n",
       "15795                       bought sweater favorite season\n",
       "Name: String, Length: 18112, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "743045a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "np.nan is an invalid document, expected byte or unicode string.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Instantiate a vectorizer \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Instantiate and fit/transform X_train using the TF-IDF vectorizer.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m tfidf \u001b[38;5;241m=\u001b[39m TfidfVectorizer()\n\u001b[0;32m----> 4\u001b[0m X_train_vectorized \u001b[38;5;241m=\u001b[39m \u001b[43mtfidf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m X_train_vectorized\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:2078\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   2071\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params()\n\u001b[1;32m   2072\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf \u001b[38;5;241m=\u001b[39m TfidfTransformer(\n\u001b[1;32m   2073\u001b[0m     norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm,\n\u001b[1;32m   2074\u001b[0m     use_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_idf,\n\u001b[1;32m   2075\u001b[0m     smooth_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmooth_idf,\n\u001b[1;32m   2076\u001b[0m     sublinear_tf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msublinear_tf,\n\u001b[1;32m   2077\u001b[0m )\n\u001b[0;32m-> 2078\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2079\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[1;32m   2080\u001b[0m \u001b[38;5;66;03m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[1;32m   2081\u001b[0m \u001b[38;5;66;03m# we set copy to False\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:1338\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1330\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1331\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1332\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1333\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1334\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1335\u001b[0m             )\n\u001b[1;32m   1336\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1338\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[1;32m   1341\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:1209\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1207\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m raw_documents:\n\u001b[1;32m   1208\u001b[0m     feature_counter \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m-> 1209\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m \u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1210\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1211\u001b[0m             feature_idx \u001b[38;5;241m=\u001b[39m vocabulary[feature]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:106\u001b[0m, in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m\"\"\"Chain together an optional series of text processing steps to go from\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03ma single document to ngrams, with or without tokenizing or preprocessing.\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03m    A sequence of tokens, possibly with pairs, triples, etc.\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decoder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 106\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m analyzer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    108\u001b[0m     doc \u001b[38;5;241m=\u001b[39m analyzer(doc)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:234\u001b[0m, in \u001b[0;36m_VectorizerMixin.decode\u001b[0;34m(self, doc)\u001b[0m\n\u001b[1;32m    231\u001b[0m     doc \u001b[38;5;241m=\u001b[39m doc\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecode_error)\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m doc \u001b[38;5;129;01mis\u001b[39;00m np\u001b[38;5;241m.\u001b[39mnan:\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnp.nan is an invalid document, expected byte or unicode string.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    236\u001b[0m     )\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m doc\n",
      "\u001b[0;31mValueError\u001b[0m: np.nan is an invalid document, expected byte or unicode string."
     ]
    }
   ],
   "source": [
    "# Instantiate a vectorizer \n",
    "# Instantiate and fit/transform X_train using the TF-IDF vectorizer.\n",
    "tfidf = TfidfVectorizer()\n",
    "X_train_vectorized = tfidf.fit_transform(X_train)\n",
    "X_train_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac041a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert vectorized X_train to a vector for easier visual inspection.\n",
    "X_train_vec = pd.DataFrame.sparse.from_spmatrix(X_train_vectorized, columns=tfidf.get_feature_names())\n",
    "X_train_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de2cfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform test data using TF-IDF Vectorizer trained on X_train, y_train\n",
    "X_test_vectorized = tfidf.transform(X_test)\n",
    "X_test_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f3eaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame for visual inspection\n",
    "X_test_vec = pd.DataFrame.sparse.from_spmatrix(X_test_vectorized, columns=tfidf.get_feature_names())\n",
    "X_test_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d3d461",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to return scores in cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5dd5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "accuracy = make_scorer(accuracy_score)\n",
    "\n",
    "#f1\n",
    "custom_f1 = make_scorer(\n",
    "    f1_score, \n",
    "    average=\"weighted\")\n",
    "\n",
    "# Precision\n",
    "multi_prec = make_scorer(\n",
    "    precision_score,\n",
    "    average=\"weighted\")\n",
    "\n",
    "# Recall\n",
    "multi_rec = make_scorer(\n",
    "    recall_score,\n",
    "    average=\"weighted\")\n",
    "\n",
    "# This function will allow for quick cross-validation of the chosen score for each of our models.\n",
    "def cross_val(model, X, y, custom_scorer, kfolds=5):\n",
    "    \"\"\" Perform cross-validated scoring and store/print results \"\"\"\n",
    "    results = cross_val_score(model, X, y, cv=kfolds, scoring=custom_scorer)\n",
    "    mean = np.mean(results)\n",
    "    median = np.median(results)\n",
    "    std = np.std(results)\n",
    "    if custom_scorer == accuracy:\n",
    "        print(f\"Mean accuracy score: \", {mean}, \".\")\n",
    "        print(f\"Median acuracy score: \", {median}, \".\")\n",
    "        print(f\"Standard Deviation in accuracy: \", {std}, \".\") \n",
    "    elif custom_scorer == custom_f1:\n",
    "        print(f\"Mean f1 score: \", {mean}, \".\")\n",
    "        print(f\"Median f1 score: \", {median}, \".\")\n",
    "        print(f\"Standard Deviation in f1 score: \", {std}, \".\") \n",
    "    elif custom_scorer == multi_prec:\n",
    "        print(f\"Mean precision score: \", {mean}, \".\")\n",
    "        print(f\"Median precision score: \", {median}, \".\")\n",
    "        print(f\"Standard Deviation in precision score: \", {std}, \".\") \n",
    "    elif custom_scorer == multi_rec:\n",
    "        print(f\"Mean recall score: \", {mean}, \".\")\n",
    "        print(f\"Median recall score: \", {median}, \".\")\n",
    "        print(f\"Standard Deviation in recall score: \", {std}, \".\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af947c4",
   "metadata": {},
   "source": [
    "## Dummy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1e68fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Dummy Classifier \n",
    "dummy_model = DummyClassifier()\n",
    "\n",
    "#Fit and Evaluate Dummy Classifier\n",
    "dummy_model.fit(X_train_vectorized, y_train)\n",
    "dummy_yhat = dummy_model.predict(X_train)\n",
    "plot_confusion_matrix(dummy_model, X_train, y_train);\n",
    "print(accuracy_score(y_train, dummy_yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47e3da4",
   "metadata": {},
   "source": [
    "We see our Dummy Model predicts our majority label, 1, for each observation. Due to class imbalance, the model performed well at 77% accuracy score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529681c0",
   "metadata": {},
   "source": [
    "## Multinomal Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3758c896",
   "metadata": {},
   "source": [
    "Now that we have preprocessed data, we can fit and evaluate a multinomial Naive Bayes classifier using cross_val_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457ec029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a MultinomialNB classifier\n",
    "multinomial_model = MultinomialNB()\n",
    "\n",
    "# Evaluate the classifier on X_train_vectorized and y_train\n",
    "multinomial_cv = cross_val_score(multinomial_model, X_train_vectorized, y_train)\n",
    "multinomial_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46af8303",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035bd6fe",
   "metadata": {},
   "source": [
    "If we guessed the plurality class every time (class 1), we would expect about 77% accuracy score (captured by our Dummy Model). So when this model is getting 78% accuracy, that is a very minimal improvement over just guessing. Let's see if we can improve that with more sophisticated modeling techinques. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38865f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#With no max_features set, we see X_train_vec and X_test_vec contains 15448 columns(unique words); this many words will create\n",
    "#a lot of \"noise\"; we want to set our max_features to only focus on the words that are appearing more often\n",
    "#setting max_features to 500 improved Multinomial NB to over 80%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c8eb5c",
   "metadata": {},
   "source": [
    "## Initial Model CV Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa6d892",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = []\n",
    "# Iterate over all algorithms\n",
    "for algorithm in [MultinomialNB(), LogisticRegression(), KNeighborsClassifier(), DecisionTreeClassifier(), XGBClassifier(), RandomForestClassifier()]:\n",
    "    # Perform cross validation\n",
    "    results = cross_val_score(algorithm, X_train_vectorized, y_train)\n",
    "    \n",
    "    # Get results & append algorithm name\n",
    "    tmp = pd.DataFrame.from_dict(results).mean(axis=0)\n",
    "    tmp = tmp.append(pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n",
    "    benchmark.append(tmp)\n",
    "    \n",
    "pd.DataFrame(benchmark).set_index('Algorithm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eeac3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#based on initial run through of algorithms, it looks like I should explore LogisticRegression, XGBoost, and RandomForestClassifier more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56960429",
   "metadata": {},
   "outputs": [],
   "source": [
    "#also want to play with vectorizor params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e3ca26",
   "metadata": {},
   "source": [
    "## Grid Searching Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9915dc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipe = Pipeline([\n",
    "           ('vect', TfidfVectorizer()),\n",
    "           ('lr', LogisticRegression(random_state=42)),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e1a698",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfce8a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr_pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf163516",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial Logistic Regression score with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710b967c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a cross validation to determine whether or not the model is overfit\n",
    "avg_lr_cv = np.mean(cross_val_score(estimator=lr_pipe, X=X_train, y=y_train, cv=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f47be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_lr_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb34df62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up grid to perform grid serach to tune hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339e058a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_params = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    'vect__max_features': (None, 500, 1000, 2000), \n",
    "    'lr__solver': ('lbfgs', 'saga', 'liblinear'),\n",
    "    'lr__penalty': ('l2', 'elasticnet'),\n",
    "    'lr__class_weight': (None, 'balanced')\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ded6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up GridSearchCV object\n",
    "grid_lr = GridSearchCV(lr_pipe, param_grid=lr_params, cv=5, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3a9ec1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fit our grid object for Logistic Regression to the training data\n",
    "#grid_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2539e467",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_parameters = grid_lr.best_params_\n",
    "\n",
    "#print('Grid Search found the following optimal parameters: ')\n",
    "#for param_name in sorted(best_parameters.keys()):\n",
    "    #print('%s: %r' % (param_name, best_parameters[param_name]))\n",
    "\n",
    "#training_preds = grid_lr.predict(X_train)\n",
    "#training_accuracy = accuracy_score(y_train, training_preds)\n",
    "#training_recall = recall_score(y_train, training_preds, average = None)\n",
    "\n",
    "#print('Training Accuracy: {:.4}%'.format(training_accuracy * 100))\n",
    "#print(training_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98e5636",
   "metadata": {},
   "source": [
    "Grid Search found the following optimal parameters: \n",
    "- lr__class_weight: None\n",
    "- lr__penalty: 'l2'\n",
    "- lr__solver: 'lbfgs'\n",
    "- vect__max_df: 0.5\n",
    "- vect__max_features: 2000\n",
    "- Training Accuracy: 89.38%\n",
    "- [0.65782557 0.96473461]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc719145",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2_params = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    'vect__max_features': (2000, 3500, 5000, 7000), \n",
    "    'lr__solver': ('lbfgs', 'saga', 'liblinear'),\n",
    "    'lr__penalty': ('l2', 'elasticnet'),\n",
    "    'lr__class_weight': (None, 'balanced')\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bf3e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_lr2 = GridSearchCV(lr_pipe, param_grid=lr2_params, cv=5, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171db945",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#grid_lr2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66355aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_parameters = grid_lr2.best_params_\n",
    "\n",
    "#print('Grid Search found the following optimal parameters: ')\n",
    "#for param_name in sorted(best_parameters.keys()):\n",
    "    #print('%s: %r' % (param_name, best_parameters[param_name]))\n",
    "\n",
    "#training_preds = grid_lr.predict(X_train)\n",
    "#training_accuracy = accuracy_score(y_train, training_preds)\n",
    "#training_recall = recall_score(y_train, training_preds, average = None)\n",
    "\n",
    "#print('Training Accuracy: {:.4}%'.format(training_accuracy * 100))\n",
    "#print(training_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1266c585",
   "metadata": {},
   "source": [
    "Grid Search found the following optimal parameters: \n",
    "- lr__class_weight: None\n",
    "- lr__penalty: 'l2'\n",
    "- lr__solver: 'saga'\n",
    "- vect__max_df: 0.5\n",
    "- vect__max_features: 3500\n",
    "- Training Accuracy: 89.38%\n",
    "- [0.65782557 0.96473461]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c16461",
   "metadata": {},
   "outputs": [],
   "source": [
    "#same training accuracy as above paraments; best accuracy = 65.7% accurate at identifying class 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d488bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing if we get better results with SMOTE with best params from first grid searc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf787dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2_pipe = ImPipeline([\n",
    "           ('vect', TfidfVectorizer(max_df=.5, max_features=2000)),\n",
    "            ('sm', SMOTE(random_state=42)),\n",
    "           ('lr', LogisticRegression(random_state=42)),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061f901f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec845eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2_yhat = lr2_pipe.predict(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9610ae9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(lr_pipe, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2d9fc9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(lr2_pipe, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b8f641",
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparing confusion matrix w/ smote (lr2) versus confusion matrix w/o smote (lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0482a73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Classification Report\n",
    "print(classification_report(y_train, lr2_yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eea8e20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cross_val(lr2_pipe, X_train, y_train, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7fd9ae",
   "metadata": {},
   "source": [
    "- Mean accuracy score:  {0.8565823084586492} .\n",
    "- Median acuracy score:  {0.8578133627829928} .\n",
    "- Standard Deviation in accuracy:  {0.0034112273820527256} ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5315e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjusting max_features params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a05a2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr3_params = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    'vect__max_features': (1500, 2000, 3000), \n",
    "    'lr__solver': ('lbfgs', 'saga', 'liblinear'),\n",
    "    'lr__penalty': ('l2', 'elasticnet'),\n",
    "    'lr__class_weight': (None, 'balanced')\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb4ca3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_lr3 = GridSearchCV(lr_pipe, param_grid=lr3_params, cv=5, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd79821d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#grid_lr3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515f8769",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_parameters = grid_lr3.best_params_\n",
    "\n",
    "#print('Grid Search found the following optimal parameters: ')\n",
    "#for param_name in sorted(best_parameters.keys()):\n",
    "    #print('%s: %r' % (param_name, best_parameters[param_name]))\n",
    "\n",
    "#training_preds = grid_lr3.predict(X_train)\n",
    "#training_accuracy = accuracy_score(y_train, training_preds)\n",
    "#training_recall = recall_score(y_train, training_preds, average = None)\n",
    "\n",
    "#print('Training Accuracy: {:.4}%'.format(training_accuracy * 100))\n",
    "#print(training_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dec5e9",
   "metadata": {},
   "source": [
    "Grid Search found the following optimal parameters: \n",
    "- lr__class_weight: None\n",
    "- lr__penalty: 'l2'\n",
    "- lr__solver: 'saga'\n",
    "- vect__max_df: 0.5\n",
    "- vect__max_features: 3000\n",
    "- Training Accuracy: 89.62%\n",
    "- [0.66332139 0.96624291]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4510782",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vect max features of 3000 seems to be optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c6dca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##utilizing current best model as best_model to test out model with Twitter data; will still\n",
    "#try to tune models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336405a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr3_pipe = ImPipeline([\n",
    "           ('vect', TfidfVectorizer(max_df=.5, max_features=3000)),\n",
    "           ('lr', LogisticRegression(random_state=42, class_weight=None, solver='saga')),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f89f49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr3_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6836774",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr3_pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0417bc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying using ngram_range of 1,2 to see if accuracy improves looking at single words and bigrams; silght improvement (.04%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe17ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr4_pipe = ImPipeline([\n",
    "           ('vect', TfidfVectorizer(max_df=.5, max_features=3000, ngram_range=(1,2))),\n",
    "           ('lr', LogisticRegression(random_state=42, class_weight=None, solver='saga')),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451a3835",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr4_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77be82d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr4)pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e01acb7",
   "metadata": {},
   "source": [
    "## Grid Searching XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d603908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate our default XGB pipeline\n",
    "XGB_pipe = ImPipeline(steps=[('vect', TfidfVectorizer(max_features=3000)), \n",
    "                             ('XGB', XGBClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe815bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our massive grid for the grid search parameters\n",
    "paramsXGB = {\n",
    "    'XGB__learning_rate': [0.1, 0.2],\n",
    "    'XGB__max_depth': range(3, 10, 2),\n",
    "    'XGB__min_child_weight': range(1, 8, 2),\n",
    "    'XGB__gamma': [0, .1, .2],\n",
    "    'XGB__subsample': [.5, .75, 1],\n",
    "    'vect__ngram_range': [(1,1), (2,2)],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3037e882",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_XGB = GridSearchCV(XGB_pipe, param_grid=paramsXGB, cv=5, verbose=3, n_jobs=-2)\n",
    "\n",
    "#Fit grid search object to our training data to check the hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10488886",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid_XGB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d34e7b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#grid_XGB.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7673366",
   "metadata": {},
   "source": [
    "- {'XGB__gamma': 0,\n",
    "- 'XGB__learning_rate': 0.2,\n",
    "- 'XGB__max_depth': 9,\n",
    "- 'XGB__min_child_weight': 5,\n",
    "- 'XGB__subsample': 0.75,\n",
    "- 'vect__ngram_range': (1, 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39922e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid_XGB.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d88063e",
   "metadata": {},
   "source": [
    "0.8630436967252351"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802e1a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_confusion_matrix(grid_XGB, X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068f2293",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(classification_report(y_train, grid_XGB.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71b1130",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #precision    recall  f1-score   support\n",
    "\n",
    "        #0       0.89      0.72      0.80      4185\n",
    "        #1       0.92      0.97      0.95     13923\n",
    "\n",
    "    #accuracy                           0.91     18108\n",
    "  # macro avg       0.91      0.85      0.87     18108\n",
    "#weighted avg       0.91      0.91      0.91     18108\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfeec3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4a4d173",
   "metadata": {},
   "source": [
    "## Grid Searching RandomForestClassfier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bced390c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#since I want to return predict proba, might not make sense to use Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec00bc9",
   "metadata": {},
   "source": [
    "# Pickling Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c89df9f",
   "metadata": {},
   "source": [
    "Playing around with pickling using current \"Best Model\"; Note: DO NOT NEED TO TEST TWEETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4a1577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "#filename = 'finalized_model.sav'\n",
    "#pickle.dump(best_model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb9200f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loaded_model = pickle.load(open(filename, 'rb'))\n",
    "#result = loaded_model.score(X_test, y_test)\n",
    "#print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f43a21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
